{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess.py has been loaded.\n",
      "available functions: ['In', 'Out', 'WordNetLemmatizer', '_', '__', '___', '__builtin__', '__builtins__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__vsc_ipynb_file__', '_dh', '_i', '_i1', '_i2', '_i3', '_i4', '_ih', '_ii', '_iii', '_oh', 'clean_text', 'exit', 'f', 'file', 'get_ipython', 'lemmatize_tokens', 'lemmatizer', 'nltk', 'open', 'pd', 'preprocess_dataframe', 'preprocess_text', 'quit', 're', 'remove_stopwords', 'stop_words', 'stopwords', 'string', 'tokenize_text', 'word_tokenize']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Florian\n",
      "[nltk_data]     Horwege\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Florian\n",
      "[nltk_data]     Horwege\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Florian\n",
      "[nltk_data]     Horwege\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# remove URLs, mentions, hashtags, and special characters\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)     # Remove mentions\n",
    "    text = re.sub(r'#', '', text)     # Remove hashtags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize_text(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize_tokens(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_dataframe(df, text_column='text'):\n",
    "    \"\"\"Preprocess an entire dataframe column containing text.\"\"\"\n",
    "    df[text_column] = df[text_column].apply(preprocess_text)\n",
    "    return df\n",
    "\n",
    "print(\"preprocess.py has been loaded.\")\n",
    "print(\"available functions:\", dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id            keyword                      location  \\\n",
      "4109   5840          hailstorm  Newton Centre, Massachusetts   \n",
      "2737   3935         devastated                     Banbridge   \n",
      "5840   8346               ruin                           NaN   \n",
      "6458   9239  suicide%20bombing                           NaN   \n",
      "2669   3831           detonate                           NaN   \n",
      "7131  10214            volcano                         Earth   \n",
      "2679   3841           detonate                 Morioh, Japan   \n",
      "6610   9466          terrorism                           NaN   \n",
      "5741   8195               riot                      Belgrade   \n",
      "2481   3560           desolate                           NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "4109  Freak #Boston #hailstorm produces a hailstorm ...       1  \n",
      "2737  'Er indoors will be devastated. RIP Arfur. #Ge...       1  \n",
      "5840                             I ruin everything ????       0  \n",
      "6458  Remembering Marlene Menahem 22 of Moshav Safsu...       1  \n",
      "2669  @WoundedPigeon http://t.co/s9soAeVcVo Detonate...       0  \n",
      "7131  1.94 earthquake occurred 5km S of Volcano Hawa...       1  \n",
      "2679  @TinyJecht Are you another Stand-user? If you ...       0  \n",
      "6610  DHS Refuses to Call Chattanooga Û÷Islamic Ter...       1  \n",
      "5741  To All The Meat-Loving Feminists Of The World ...       0  \n",
      "2481  Me watching Law &amp; Order (IB: @sauldale305)...       1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/external/train.csv')\n",
    "sample = df.sample(10)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id            keyword                      location  \\\n",
      "4109   5840          hailstorm  Newton Centre, Massachusetts   \n",
      "2737   3935         devastated                     Banbridge   \n",
      "5840   8346               ruin                           NaN   \n",
      "6458   9239  suicide%20bombing                           NaN   \n",
      "2669   3831           detonate                           NaN   \n",
      "7131  10214            volcano                         Earth   \n",
      "2679   3841           detonate                 Morioh, Japan   \n",
      "6610   9466          terrorism                           NaN   \n",
      "5741   8195               riot                      Belgrade   \n",
      "2481   3560           desolate                           NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "4109  freak produce hailstorm business autobody repa...       1  \n",
      "2737                    er indoors devastated rip arfur       1  \n",
      "5840                                    ruin everything       0  \n",
      "6458  remembering marlene menahem 22 moshav safsufa ...       1  \n",
      "2669                                    detonate ft mop       0  \n",
      "7131  194 earthquake occurred 5km volcano hawaii 010...       1  \n",
      "2679            another standuser detonate killer queen       0  \n",
      "6610  dhs refuse call chattanooga û÷islamic terrori...       1  \n",
      "5741  meatloving feminist world riot grill arrived p...       0  \n",
      "2481                     watching law amp order ib vine       1  \n"
     ]
    }
   ],
   "source": [
    "clean_sample = preprocess_dataframe(sample)\n",
    "print(clean_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
